{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from itertools import groupby, count\n",
    "from collections import deque\n",
    "from io import StringIO\n",
    "import ctypes as ct\n",
    "import re\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate for building complement of a DNA sequence\n",
    "compl = str.maketrans('ATGCNSWRYKMatgcnswrykm', 'TACGNWSYRMKtacgnwsyrmk')\n",
    "cg_pat = re.compile(\"(\\d+)([=XID])\")\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgHelpFormatter(argparse.HelpFormatter):\n",
    "    '''\n",
    "    Formatter adding default values to help texts.\n",
    "    '''\n",
    "    def __init__(self, prog):\n",
    "        super().__init__(prog)\n",
    "\n",
    "    ## https://stackoverflow.com/questions/3853722\n",
    "    #def _split_lines(self, text, width):\n",
    "    #   if text.startswith('R|'):\n",
    "    #       return text[2:].splitlines()  \n",
    "    #   # this is the RawTextHelpFormatter._split_lines\n",
    "    #   return argparse.HelpFormatter._split_lines(self, text, width)\n",
    "\n",
    "    def _get_help_string(self, action):\n",
    "        text = action.help\n",
    "        if  action.default is not None and \\\n",
    "            action.default != argparse.SUPPRESS and \\\n",
    "            'default:' not in text.lower():\n",
    "            text += ' (default: {})'.format(action.default)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(args=None):\n",
    "    parser = argparse.ArgumentParser(description='Estimates read starts (transposase insertion sites) for ONT rapid libraries',\n",
    "                                     formatter_class=ArgHelpFormatter, \n",
    "                                     add_help=False)\n",
    "\n",
    "    main_group = parser.add_argument_group('Main Options')\n",
    "    main_group.add_argument('reads',\n",
    "                            nargs='+',\n",
    "                            help='fastq files or path to directories containing fastq files (recursion depth 1)')\n",
    "    main_group.add_argument('genome',\n",
    "                            help='Fasta file containing the genomic sequences that is searched for insertion sites.')\n",
    "    main_group.add_argument('adapter',\n",
    "                            help='Transposon Y adapter sequence')\n",
    "    main_group.add_argument('--prefix',\n",
    "                            help=\"filename for readstarts in tap seperated value (.tsv) format\",\n",
    "                            default=\"readstarts\")\n",
    "    #main_group.add_argument('--verbose_out_file',\n",
    "    #                        help=\"print detailed, human readable information about each read to this file\")\n",
    "    #main_group.add_argument('--verbose_col_width',\n",
    "    #                        help=\"column width for verbose output\",\n",
    "    #                        type=int,\n",
    "    #                        default=250)\n",
    "    main_group.add_argument('--plot',\n",
    "                            help='plot results of gaussian approximation',\n",
    "                            action='store_true')\n",
    "    main_group.add_argument('--circular',\n",
    "                            action=\"store_true\")\n",
    "    main_group.add_argument('--strip',\n",
    "                            help=\"number of bases stripped from alignments to cope with coincidently identical sequences\",\n",
    "                            type=int,\n",
    "                            default=5)\n",
    "    main_group.add_argument('--wordsize',\n",
    "                            help='',\n",
    "                            type=int,\n",
    "                            default=12)\n",
    "    main_group.add_argument('--max_dist',\n",
    "                            help='''max distance between an adapter and a genome alignment to perform pairwise-alignment \n",
    "                                 in order to identify the exact transition point''',\n",
    "                            type=int,\n",
    "                            default=200)\n",
    "    main_group.add_argument('--min_readlength',\n",
    "                            help=\"min length of reads to be analyzed\",\n",
    "                            type=int,\n",
    "                            default=500)\n",
    "    main_group.add_argument('--processes',\n",
    "                            type=int,\n",
    "                            default=6)\n",
    "    main_group.add_argument('--batchsize',\n",
    "                            type=int,\n",
    "                            default=8000)\n",
    "    \n",
    "    align_group = parser.add_argument_group('Alignment Options')\n",
    "    align_group.add_argument('--match',\n",
    "                             help='match score',\n",
    "                             type=int,\n",
    "                             default=1)\n",
    "    align_group.add_argument('--mismatch',\n",
    "                             help='mismatch penalty',\n",
    "                             type=int,\n",
    "                             default=-2)\n",
    "    align_group.add_argument('--gap_open',\n",
    "                             help='gap open penalty',\n",
    "                             type=int,\n",
    "                             default=-4)\n",
    "    align_group.add_argument('--gap_extension',\n",
    "                             help='gap extension penalty',\n",
    "                             type=int,\n",
    "                             default=-1)\n",
    "\n",
    "    filter_group = parser.add_argument_group('Filter Options')\n",
    "    filter_group.add_argument('--mean',\n",
    "                              help='mean of per-base difference of actual sequence length from read length',\n",
    "                              type=float)\n",
    "    filter_group.add_argument('--std',\n",
    "                              help='standard deviation of per-base difference of actual sequence length from read length',\n",
    "                              type=float)\n",
    "    filter_group.add_argument('--min_blen',\n",
    "                              help=\"min produced alignment length (including errors)\",\n",
    "                              type=int,\n",
    "                              default=20)\n",
    "    filter_group.add_argument('--min_adapter_blen',\n",
    "                              help=\"min produced alignment length (including errors)\",\n",
    "                              type=int,\n",
    "                              default=50)\n",
    "    filter_group.add_argument('--min_genome_blen',\n",
    "                              help=\"min produced alignment length (including errors)\",\n",
    "                              type=int,\n",
    "                              default=50)\n",
    "    filter_group.add_argument('--f_window',\n",
    "                              help=\"sequence window around the position of transition from \"+\\\n",
    "                                   \"the adapter sequence to the chromosome sequence\",\n",
    "                              type=int,\n",
    "                              default=7)\n",
    "    filter_group.add_argument('--f_max_w_err',\n",
    "                              help=\"max amount of errors (insertions, deletions, mismatches) \"+\\\n",
    "                                   \"within the specified sequence window\",\n",
    "                              type=int,\n",
    "                              default=3)\n",
    "    filter_group.add_argument('--f_max_mm_strech',\n",
    "                              help=\"max amount of deletions or insertions in the whole realignment\",\n",
    "                              type=int,\n",
    "                              default=3)\n",
    "\n",
    "    help_group = parser.add_argument_group('Help')\n",
    "    help_group.add_argument('-h', '--help', \n",
    "                            action='help', \n",
    "                            default=argparse.SUPPRESS,\n",
    "                            help='Show this help message and exit.')\n",
    "    if args:\n",
    "        return parser.parse_args(args)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_minimap2(ref_fn, fq_fn, paf_fn):\n",
    "    cmd ='minimap2 -x map-ont -c --eqx --secondary=no -t 4 {} {} >{} 2> /dev/null'.format(ref_fn, fq_fn, paf_fn)\n",
    "    #print('Running:', cmd)\n",
    "    return os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paf(fn, cigar=False):\n",
    "    usecols = list(range(12))\n",
    "    names = [\"qid\", \"qlen\", \"qst\", \"qen\", \"strand\", \"subj\", \n",
    "             \"slen\", \"sst\", \"sen\", \"mlen\", \"blen\", \"mapq\"]\n",
    "    dtype = {\"qid\": str, \"qlen\": np.int32, \"qst\": np.int32, \n",
    "             \"qen\": np.int32, \"strand\": str, \"subj\": str,\n",
    "             \"slen\": np.int32, \"sst\": np.int32, \"sen\": np.int32, \n",
    "             \"mlen\": np.int32, \"blen\": np.int32, \"mapq\": np.int32}\n",
    "    converters = {}\n",
    "    if cigar:\n",
    "        usecols.append(22)\n",
    "        names.append('cg')\n",
    "        converters['cg'] = lambda x: x.split(':')[-1]\n",
    "    return pd.read_csv(fn, sep='\\t', header=None,\n",
    "                       usecols=usecols,\n",
    "                       names=names,\n",
    "                       dtype=dtype,\n",
    "                       converters=converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_query_st(row):\n",
    "    trimmed_query = 0\n",
    "    trimmed_subject = 0\n",
    "    if row.trans_order == 1.:\n",
    "        cg = row.cg_ad\n",
    "        qen = row.qen_ad\n",
    "    else:\n",
    "        cg = row.cg_gn\n",
    "        qen = row.qen_gn\n",
    "    cg_list = re.findall(cg_pat, cg)\n",
    "    for bases,op in reversed(cg_list):\n",
    "        bases = int(bases)\n",
    "        if op == \"=\" and bases >= args.wordsize:\n",
    "            return qen - trimmed_query, trimmed_subject\n",
    "            break\n",
    "        if op == \"=\" or op == 'X':\n",
    "            trimmed_query += bases\n",
    "            trimmed_subject += bases\n",
    "        elif op == 'I':\n",
    "            trimmed_query += bases\n",
    "        else: # == D\n",
    "            trimmed_subject += bases\n",
    "    # unsuccessful\n",
    "    return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_query_en(row):\n",
    "    trimmed_query = 0\n",
    "    trimmed_subject = 0\n",
    "    if row.trans_order == 1.:\n",
    "        cg = row.cg_gn\n",
    "        qst = row.qst_gn\n",
    "    else:\n",
    "        cg = row.cg_ad\n",
    "        qst = row.qst_ad\n",
    "    for m in re.finditer(cg_pat, cg):\n",
    "        bases, op = int(m.group(1)), m.group(2)\n",
    "        if op == \"=\" and bases >= args.wordsize:\n",
    "            return qst + trimmed_query, trimmed_subject\n",
    "            break\n",
    "        if op == \"=\" or op == 'X':\n",
    "            trimmed_query += bases\n",
    "            trimmed_subject += bases\n",
    "        elif op == 'I':\n",
    "            trimmed_query += bases\n",
    "        else: # == D\n",
    "            trimmed_subject += bases\n",
    "    # unsuccessful\n",
    "    return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_seq(df, sel, fix=True):\n",
    "    df['ref1_trim'], df['ref2_trim'] = 0, 0\n",
    "    \n",
    "    cg_ad = df.cg_ad.str.replace('D|I', 'X')\n",
    "    cg_gn = df.cg_gn.str.replace('D|I', 'X')\n",
    "    \n",
    "    sel_ = sel & (df.trans_order == 1.) & (cg_ad.str.rstrip('=').str.rsplit('X', n=1).str[-1].astype(np.float32) >= args.wordsize) # & (df.strand_ad == '+')\n",
    "    df.loc[sel_ , 'query_st'] = df[sel_].qen_ad\n",
    "    sel_ = sel & (df.trans_order == 1.) & (cg_gn.str.split('=', n=1).str[0].astype(np.float32) >= args.wordsize) # & (df.strand_ad == '+')\n",
    "    df.loc[sel_ , 'query_en'] = df[sel_].qst_gn\n",
    "    \n",
    "    sel_ = sel & (df.trans_order == -1.) & (cg_gn.str.rstrip('=').str.rsplit('X', n=1).str[-1].astype(np.float32) >= args.wordsize) # & (df.strand_ad == '+') \n",
    "    df.loc[sel_ , 'query_st'] = df[sel_].qen_gn\n",
    "    sel_ = sel & (df.trans_order == -1.) & (cg_ad.str.split('=', n=1).str[0].astype(np.float32) >= args.wordsize) # & (df.strand_ad == '+')\n",
    "    df.loc[sel_ , 'query_en'] = df[sel_].qst_ad\n",
    "    \n",
    "    if fix:\n",
    "        # fix query end & start of reads with insufficient terminal alignments\n",
    "        df.loc[sel & df.query_st.isnull(), ['query_st', 'ref1_trim']] = pd.DataFrame(\n",
    "            df.loc[sel & df.query_st.isnull()].apply(lambda row: fix_query_st(row), axis=1).values.tolist(), \n",
    "            index=df.loc[sel & df.query_st.isnull()].index, columns=['query_st', 'ref1_trim']\n",
    "        )\n",
    "        df.loc[sel & df.query_en.isnull(), ['query_en', 'ref2_trim']] = pd.DataFrame(\n",
    "            df.loc[sel & df.query_en.isnull()].apply(lambda row: fix_query_en(row), axis=1).values.tolist(), \n",
    "            index=df.loc[sel & df.query_en.isnull()].index, columns=['query_en', 'ref2_trim']\n",
    "        )\n",
    "    \n",
    "    sel_ = sel & df.query_st.notnull()\n",
    "    df.loc[sel, 'query_st'] -= args.strip\n",
    "    df.loc[sel, 'ref1_trim'] += args.strip\n",
    "    sel_ = sel & df.query_en.notnull()\n",
    "    df.loc[sel, 'query_en'] += args.strip\n",
    "    df.loc[sel, 'ref2_trim'] += args.strip\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_length_stats(df):\n",
    "    dfs = []\n",
    "    # add length of read seq that aligns as \"qalen\"\n",
    "    dfs.append((df[df.subj.notnull()].qen - df[df.subj.notnull()].qst).to_frame(name='qalen'))\n",
    "    # add length of genome seq that aligns as \"salen\"\n",
    "    dfs.append((df[df.subj.notnull()].sen - df[df.subj.notnull()].sst).abs().to_frame(name='salen'))\n",
    "    ## add match, mismatch, insertion and deletion counts\n",
    "    #two_groups = '(?P<digit>[0-9]*)(?P<letter>[=XID])'\n",
    "    #d = df[df.subj_gn.notnull()].cg_gn.str.extractall(two_groups)\n",
    "    #d.loc[:, 'digit'] = d.digit.astype(\"float32\")\n",
    "    #for letter in ['=', 'X', 'I', 'D']:\n",
    "    #    dfs.append(d.loc[d.letter == letter].groupby(level=0).agg('sum').rename(columns = {'digit':letter}))\n",
    "    stats = pd.concat(dfs, axis=1).fillna(0.)\n",
    "    data = (stats.salen - stats.qalen)/stats.qalen\n",
    "    args.mean, args.std = norm.fit(data)\n",
    "    if args.plot:\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "        ax.hist(data, bins=100, density=True)\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "        x = np.linspace(xmin, xmax, 200)\n",
    "        y = norm.pdf(x, args.mean, args.std)\n",
    "        ax.plot(x, y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_iter_items(iterable):\n",
    "        counter = count()\n",
    "        deque(zip(iterable, counter), maxlen=0)  # (consume at C speed)\n",
    "        return next(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigar_str(query, subj):\n",
    "    cs = []\n",
    "    for q,s in zip(query, subj):\n",
    "        if q == s:\n",
    "            cs.append('=')\n",
    "        elif q == '-':\n",
    "            cs.append('D')\n",
    "        elif s == '-':\n",
    "            cs.append('I')\n",
    "        else:\n",
    "            cs.append('X')\n",
    "    return \"\".join(cs)\n",
    "    #return \"\".join([\"{}{}\".format(count_iter_items(g), k) for k,g in groupby(cs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrace_css_gapped(ops, s1len, cs=[]):\n",
    "    traces = []\n",
    "    if sum(ops.shape[1:]) == 2:\n",
    "        #return [\"\".join([\"{}{}\".format(count_iter_items(g), k) for k,g in groupby(cs)])]\n",
    "        return [\"\".join(cs)]\n",
    "    if ops[0,-1,-1]: # insertion\n",
    "        traces += ( backtrace_css_gapped(ops[:,:,:-1], s1len, ['I'] + cs) )\n",
    "    if ops[1,-1,-1]: # deletion\n",
    "        traces += ( backtrace_css_gapped(ops[:,:-1,:], s1len, ['D'] + cs) )\n",
    "    if ops[2,-1,-1]: # match\n",
    "        traces += ( backtrace_css_gapped(ops[:,:-1,:-1], s1len, ['='] + cs) )\n",
    "    if ops[3,-1,-1]: # mismatch\n",
    "        traces += ( backtrace_css_gapped(ops[:,:-1,:-1], s1len, ['X'] + cs) )\n",
    "    if ops[4,-1,-1]: # free gap\n",
    "        if ops.shape[1] > s1len + 1:\n",
    "            jump_to = s1len + 1\n",
    "            char = '>'\n",
    "        else:\n",
    "            jump_to = ops[5,:,-1].argmax() + 1\n",
    "            char = '<'\n",
    "        stepsize = ops.shape[1] - jump_to\n",
    "        traces += ( backtrace_css_gapped(ops[:,:jump_to,:], s1len, [char]*stepsize + cs) )\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapped_twinalign(query, subj1, subj2, m=1, mm=-2, go=-4, ge=-1):\n",
    "    qlen, s1len, s2len = len(query), len(subj1), len(subj2)\n",
    "    subj = subj1 + subj2\n",
    "    min_val = np.iinfo(np.int32).min\n",
    "    # stores operations (insertion, deletion, match, mismatch, endgap_start, endgap_end) that maximize the score\n",
    "    ops = np.zeros(shape=(6, s1len+s2len+1, qlen+1), dtype=np.bool_)\n",
    "    ops[2,0,0] = True\n",
    "    ops[0,0,1:] = True\n",
    "    ops[1,1:s1len,0] = True\n",
    "    ops[4,s1len:,0] = True\n",
    "    ops[5,0,0] = True\n",
    "    ops[5,s1len,0] = True\n",
    "    # stores the best partial alignment scores\n",
    "    scores = np.empty(shape=(s1len+s2len+1, qlen+1), dtype=np.int32)\n",
    "    scores[0,0] = 0\n",
    "    scores[0,1:] = np.arange(go + ge, go + (qlen+1)*ge, ge)\n",
    "    scores[1:s1len+1,0] = np.arange(go + ge, go + (s1len+1)*ge, ge)\n",
    "    \n",
    "    op_scores = np.empty(shape=(5,), dtype=np.int32)\n",
    "    for i in range(1,s1len):\n",
    "        for j in range(1,qlen+1):\n",
    "            # insertion\n",
    "            op_scores[0] = scores[i,j-1] + (not ops[0,i,j-1]) * go + ge\n",
    "            # deletion\n",
    "            op_scores[1] = scores[i-1,j] + (not ops[1,i-1,j]) * go + ge\n",
    "            # match/mismatch\n",
    "            if (subj[i-1] == query[j-1]):\n",
    "                op_scores[2] = scores[i-1,j-1] + m\n",
    "                op_scores[3] = min_val\n",
    "            else:\n",
    "                op_scores[2] = min_val\n",
    "                op_scores[3] = scores[i-1,j-1] + mm\n",
    "            \n",
    "            scores[i,j] = op_scores[:4].max()\n",
    "            ops[:4,i,j] = op_scores[:4] == scores[i,j]\n",
    "    for i in range(s1len,s1len+1):\n",
    "        for j in range(1,qlen+1):\n",
    "            # insertion\n",
    "            op_scores[0] = scores[i,j-1] + (not ops[0,i,j-1]) * go + ge\n",
    "            # deletion\n",
    "            op_scores[1] = scores[i-1,j] + (not ops[1,i-1,j]) * go + ge\n",
    "            # match/mismatch\n",
    "            if (subj[i-1] == query[j-1]):\n",
    "                op_scores[2] = scores[i-1,j-1] + m\n",
    "                op_scores[3] = min_val\n",
    "            else:\n",
    "                op_scores[2] = min_val\n",
    "                op_scores[3] = scores[i-1,j-1] + mm\n",
    "            # free end gap\n",
    "            max_in_col = scores[:i,j].argmax()\n",
    "            op_scores[4] = scores[max_in_col,j]\n",
    "            \n",
    "            scores[i,j] = op_scores.max()\n",
    "            ops[:4,i,j] = op_scores[:4] == scores[i,j]\n",
    "            if op_scores[4] == scores[i,j]:\n",
    "                ops[4,i,j] = True # gap start\n",
    "                ops[5,max_in_col,j] = True # gap end\n",
    "            #else:\n",
    "            #    ops[5,i,j] = True # gap end\n",
    "            ops[5,i,j] = True # gap end\n",
    "    scores[s1len:,0] = 0\n",
    "    for i in range(s1len+1,s1len+s2len+1):\n",
    "        for j in range(1,qlen+1):\n",
    "            # insertion\n",
    "            op_scores[0] = scores[i,j-1] + (not ops[0,i,j-1]) * go + ge\n",
    "            # deletion\n",
    "            op_scores[1] = scores[i-1,j] + (not ops[1,i-1,j]) * go + ge\n",
    "            # match/mismatch\n",
    "            if (subj[i-1] == query[j-1]):\n",
    "                op_scores[2] = scores[i-1,j-1] + m\n",
    "                op_scores[3] = min_val\n",
    "            else:\n",
    "                op_scores[2] = min_val\n",
    "                op_scores[3] = scores[i-1,j-1] + mm\n",
    "            # free start gap\n",
    "            op_scores[4] = scores[s1len,j]\n",
    "            \n",
    "            scores[i,j] = op_scores.max()\n",
    "            ops[:5,i,j] = op_scores == scores[i,j]\n",
    "            if ops[4,i,j]:\n",
    "                ops[5,s1len,j] = True # gap end\n",
    "    return scores, ops#np.packbits(ops, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_row(row):\n",
    "    scores,_ = gapped_twinalign(row.query_seq, row.ref1, row.ref2)\n",
    "    #row['score'] = score\n",
    "    return scores[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_align_row(row):\n",
    "    if pd.isnull(row.ref1):\n",
    "        #row['score'] = np.nan\n",
    "        #row['transisions'] = None\n",
    "        return row\n",
    "    qlen, s1len, s2len = len(row.query_seq), len(row.ref1), len(row.ref2)\n",
    "    query, subj = row.query_seq.encode(\"utf8\"), (row.ref1+row.ref2).encode(\"utf8\")\n",
    "    align(query, subj, \n",
    "          qlen, s1len, s2len,\n",
    "          args.match, args.mismatch, args.gap_open, args.gap_extension,\n",
    "          scores_pp, *ops_pp)\n",
    "    score = scores[s1len+s2len, qlen]\n",
    "    #print(row.query_seq, row.ref1, row.ref2)\n",
    "    #return scores[s1len+s2len, qlen]\n",
    "    \n",
    "    transitions = np.zeros(shape=(s1len+1, s2len+1), dtype=np.bool_)\n",
    "    if transitions.flags['C_CONTIGUOUS'] == False:\n",
    "        transitions = np.ascontiguousarray(transitions, dtype=transitions.dtype)\n",
    "    transitions_pp = (transitions.ctypes.data + np.arange(transitions.shape[0]) * transitions.strides[0]).astype(np.uintp)\n",
    "    backtrace(*ops_pp,\n",
    "              qlen, s1len, s2len,\n",
    "              transitions_pp)\n",
    "    transitions_hr = list(zip(*np.where(transitions)))\n",
    "    \n",
    "    row['score'] = score\n",
    "    row['transitions'] = transitions_hr\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref1(row):\n",
    "    if row.trans_order == 1.:\n",
    "        subj = adapter.loc[row.subj_ad]\n",
    "        strand = row.strand_ad\n",
    "        sst = row.sst_ad\n",
    "        sen = row.sen_ad\n",
    "    else:\n",
    "        subj = genome.loc[row.subj_gn]\n",
    "        strand = row.strand_gn\n",
    "        sst = row.sst_gn\n",
    "        sen = row.sen_gn\n",
    "    \n",
    "    # +\n",
    "    #adapter.loc[row.subj_ad].seq[(row.sen_ad - int(row.ref1_trim)) : (row.sen_ad - int(row.ref1_trim)) + int(row.max_ref_len)]\n",
    "    # genome.loc[row.subj_gn].seq[(row.sen_gn - int(row.ref1_trim)) : (row.sen_gn - int(row.ref1_trim)) + int(row.max_ref_len)]\n",
    "    # -\n",
    "    #adapter.loc[row.subj_ad].seq[(row.sst_ad + int(row.ref1_trim)) - int(row.max_ref_len) : (row.sst_ad + int(row.ref1_trim))]\n",
    "    # genome.loc[row.subj_gn].seq[(row.sst_gn + int(row.ref1_trim)) - int(row.max_ref_len) : (row.sst_gn + int(row.ref1_trim))]\n",
    "    \n",
    "    if strand == '+':\n",
    "        ref1 = subj.seq[(sen - int(row.ref1_trim))                                : (sen - int(row.ref1_trim)) + int(row.max_ref_len)]\n",
    "    else:\n",
    "        ref1 = subj.seq[max((sst + int(row.ref1_trim)) - int(row.max_ref_len), 0) : (sst + int(row.ref1_trim))]\n",
    "        ref1 = ref1.translate(compl)[::-1]\n",
    "    \n",
    "    return ref1\n",
    "    \n",
    "def get_ref2(row):\n",
    "    if row.trans_order == 1.:\n",
    "        subj = genome.loc[row.subj_gn]\n",
    "        strand = row.strand_gn\n",
    "        sst = row.sst_gn\n",
    "        sen = row.sen_gn\n",
    "    else:\n",
    "        subj = adapter.loc[row.subj_ad]\n",
    "        strand = row.strand_ad\n",
    "        sst = row.sst_ad\n",
    "        sen = row.sen_ad\n",
    "    \n",
    "    # +\n",
    "    # genome.loc[row.subj_gn].seq[(row.sst_gn + int(row.ref2_trim)) - int(row.max_ref_len) : (row.sst_gn + int(row.ref2_trim))], axis=1)\n",
    "    #adapter.loc[row.subj_ad].seq[(row.sst_ad + int(row.ref2_trim)) - int(row.max_ref_len) : (row.sst_ad + int(row.ref2_trim))], axis=1)\n",
    "    # -\n",
    "    # genome.loc[row.subj_gn].seq[(row.sen_gn - int(row.ref2_trim)) : (row.sen_gn - int(row.ref2_trim)) + int(row.max_ref_len)], axis=1)\n",
    "    #adapter.loc[row.subj_ad].seq[(row.sen_ad - int(row.ref2_trim)) : (row.sen_ad - int(row.ref2_trim)) + int(row.max_ref_len)], axis=1)\n",
    "    \n",
    "    if strand == '+':\n",
    "        ref2 = subj.seq[max((sst + int(row.ref2_trim)) - int(row.max_ref_len), 0) : (sst + int(row.ref2_trim))]\n",
    "    else:\n",
    "        ref2 = subj.seq[(sen - int(row.ref2_trim))                                : (sen - int(row.ref2_trim)) + int(row.max_ref_len)]\n",
    "        ref2 = ref2.translate(compl)[::-1]\n",
    "    \n",
    "    return ref2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_align(query_seq, ref1, ref2):\n",
    "    qlen, s1len, s2len = len(query_seq), len(ref1), len(ref2)\n",
    "    query, subj = query_seq.encode(\"utf8\"), (ref1+ref2).encode(\"utf8\")\n",
    "    align(query, subj, \n",
    "          qlen, s1len, s2len,\n",
    "          args.match, args.mismatch, args.gap_open, args.gap_extension,\n",
    "          scores_pp, *ops_pp)\n",
    "    score = scores[s1len+s2len, qlen]\n",
    "    \n",
    "    transitions = np.zeros(shape=(s1len+1, s2len+1), dtype=np.bool_)\n",
    "    if transitions.flags['C_CONTIGUOUS'] == False:\n",
    "        transitions = np.ascontiguousarray(transitions, dtype=transitions.dtype)\n",
    "    transitions_pp = (transitions.ctypes.data + np.arange(transitions.shape[0]) * transitions.strides[0]).astype(np.uintp)\n",
    "    backtrace(*ops_pp,\n",
    "              qlen, s1len, s2len,\n",
    "              s1len+s2len, qlen, 0, s2len, \n",
    "              transitions_pp)\n",
    "    transitions_hr = list(zip(*np.where(transitions)))\n",
    "\n",
    "    print(score)\n",
    "    print(scores[:s1len+s2len+1, :qlen+1])\n",
    "    print(ops[:,:s1len+s2len+1, :qlen+1])\n",
    "    print(transitions_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(['/vol/seqpro2019/MLinder_SMART/58_Serratia_sp._strain_KS8B.ONT.fastq', \n",
    "                 '/vol/seqpro2019/MLinder_SMART/analysis/KS8B_segmented_5000_1.fa',\n",
    "                 '/vol/seqpro2019/MLinder_SMART/analysis/KS8B_segmented_5000_2.fa', \n",
    "                 '--prefix', '/vol/seqpro2019/MLinder_SMART/analysis/Run00408/KS8B_segmented_5000', \n",
    "                 '--plot', '--processes', '8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_files = []\n",
    "for entry in args.reads:\n",
    "    if os.path.isfile(entry) and (entry.endswith(\".fastq\") or entry.endswith(\".fq\")):\n",
    "        fq_files.append(entry)\n",
    "    else:\n",
    "        fq_files.extend([os.path.join(entry, f) for f in os.listdir(entry) if os.path.isfile(os.path.join(entry, f)) \\\n",
    "            and (f.endswith(\".fastq\") or f.endswith(\".fq\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - reading adapter sequence ...\n",
      "       2500 adapter sequence(s) in fasta file\n",
      " - reading genome fasta ...\n",
      "       2500 genomic sequence(s) in fasta file\n",
      " - reading fastq files ...\n",
      "     223187 reads in dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adapter = {}\n",
    "print(\" - reading adapter sequence ...\")\n",
    "for record in SeqIO.parse(args.adapter, \"fasta\"):\n",
    "    adapter[str(record.id)] = str(record.seq)\n",
    "adapter = pd.DataFrame.from_dict(adapter, orient='index', columns=['seq'], dtype='string')\n",
    "print('{:>11} adapter sequence(s) in fasta file'.format(len(adapter)))\n",
    "\n",
    "print(\" - reading genome fasta ...\")\n",
    "genome = {}\n",
    "for record in SeqIO.parse(args.genome, \"fasta\"):\n",
    "    genome[str(record.id)] = str(record.seq)\n",
    "genome = pd.DataFrame.from_dict(genome, orient='index', columns=['seq'], dtype='string')\n",
    "print('{:>11} genomic sequence(s) in fasta file'.format(len(genome)))\n",
    "\n",
    "print(\" - reading fastq files ...\")\n",
    "reads = {}\n",
    "#reads = pd.DataFrame([], {'seq':Seq})\n",
    "for fqFile in fq_files:\n",
    "    for record in SeqIO.parse(fqFile, \"fastq\"):\n",
    "        reads[str(record.id)] = str(record.seq)\n",
    "reads = pd.DataFrame.from_dict(reads, orient='index', columns=['seq'], dtype='string')\n",
    "print(\"{:>11} reads in dataset\\n\".format(len(reads)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = '{}_tmp'.format(args.prefix)\n",
    "if os.path.exists(tmp_dir):\n",
    "    shutil.rmtree(tmp_dir)\n",
    "os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - performing reads to adapter reference mapping ...\n",
      "    1378744         primary alignments against adapter sequence(s)\n",
      "     689352  50.0 % against (+) strand\n",
      "     689392  50.0 % against (-) strand\n",
      "     219997  98.6 % of reads align against any adapter sequence\n"
     ]
    }
   ],
   "source": [
    "print(\" - performing reads to adapter reference mapping ...\")\n",
    "fq_fn = \" \".join(fq_files)\n",
    "ref_fn = args.adapter\n",
    "paf_fn = os.path.join(tmp_dir, \"adapter_alignment.paf\")\n",
    "exit_code = run_minimap2(ref_fn, fq_fn, paf_fn)\n",
    "if exit_code:\n",
    "    print('ERROR: adapter reference mapping failed with exit code', exit_code)\n",
    "    exit(1)\n",
    "ad_algn_df = parse_paf(paf_fn, cigar=True)#.set_index('qid')\n",
    "print(\"{:>11} {:>7} primary alignments against adapter sequence(s)\".format(len(ad_algn_df), \"\"))\n",
    "c = sum(ad_algn_df.strand == '+')\n",
    "print(\"{:>11} {:>5.1f} % against (+) strand\".format(c, c/len(ad_algn_df)*100.))\n",
    "c = sum(ad_algn_df.strand == '-')\n",
    "print(\"{:>11} {:>5.1f} % against (-) strand\".format(c, c/len(ad_algn_df)*100.))\n",
    "c = len(set(ad_algn_df.qid))\n",
    "print(\"{:>11} {:>5.1f} % of reads align against any adapter sequence\".format(c, c/len(reads)*100.))\n",
    "#df = pd.merge(df, algn_df, how='outer', left_index=True, right_index=True, sort=False, suffixes=('_x', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - performing reads to genome reference mapping ...\n",
      "    1375945         primary alignments against genomic sequence(s)\n",
      "     688379  50.0 % against (+) strand\n",
      "     687566  50.0 % against (-) strand\n",
      "     220011  98.6 % of reads align against any genome sequence\n"
     ]
    }
   ],
   "source": [
    "print(\" - performing reads to genome reference mapping ...\")\n",
    "ref_fn = args.genome\n",
    "paf_fn = os.path.join(tmp_dir, \"genome_alignment.paf\")\n",
    "exit_code = run_minimap2(ref_fn, fq_fn, paf_fn)\n",
    "if exit_code:\n",
    "    print('ERROR: adapter reference mapping failed with exit code', exit_code)\n",
    "    exit(1)\n",
    "gn_algn_df = parse_paf(paf_fn, cigar=True)#.set_index('qid')\n",
    "print(\"{:>11} {:>7} primary alignments against genomic sequence(s)\".format(len(gn_algn_df), \"\"))\n",
    "c = sum(gn_algn_df.strand == '+')\n",
    "print(\"{:>11} {:>5.1f} % against (+) strand\".format(c, c/len(gn_algn_df)*100.))\n",
    "c = sum(gn_algn_df.strand == '-')\n",
    "print(\"{:>11} {:>5.1f} % against (-) strand\".format(c, c/len(gn_algn_df)*100.))\n",
    "c = len(set(gn_algn_df.qid))\n",
    "print(\"{:>11} {:>5.1f} % of reads align against any genome sequence\".format(c, c/len(reads)*100.))\n",
    "#df = pd.merge(df, algn_df, how='outer', left_index=True, right_index=True, sort=False, suffixes=('_ad', '_gn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - determining statistics about per-base difference ([align. subject len] - [align. query len]) / [align. query len] al from genome alignments\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFoCAYAAABt6zNZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAd0ElEQVR4nO3df5BdZ33f8fdXWmklS1rJttZ2g0HCtGBiJza1wIVAYWomBBJaijMTiGmYgWJCxk2bTmmdKSaaDgTCJOmUNCHxDL+GXwUyhjZxExgaOxMgJLMOAVtEkFLbYMDyylirvSvtrrR6+sc5d3W9Wmnv3XvuPc/e837N3Lm655x77vPs0d3PPs95nnMipYQkScrHproLIEmSnsxwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMjNWx4fu3bs37d+/v46PliSpFvfdd9/RlNJkN9vWEs779+9namqqjo+WJKkWEfFwt9varS1JUmYMZ0mSMmM4S5KUGcNZkqTMGM6SJGXGcJYkKTOGsyRJmTGcJUnKjOEsSVJmDGdJkjJjOEuSlBnDWZKkzBjOkiRlppa7Ukk61/7b717+90Pv/ukaSyKpbracJUnKjOEsSVJmDGdJkjJjOEuSlBnDWZKkzBjOkiRlxnCWJCkzhrMkSZkxnCVJyozhLElSZgxnSZIyYzhLkpQZw1mSpMwYzpIkZcZwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMmM4S5KUGcNZkqTMdBXOEfHRiPhBRByPiG9FxL/uWHdTRByOiBMRcU9E7BtccSVJGn3dtpzfBexPKU0A/xx4R0TcEBF7gbuAO4BLgCngkwMpqSRJDTHWzUYppUOdL8vHM4AbgEMppU8DRMRB4GhEXJ1SOlxxWSVJaoSuzzlHxO9FxAngMPAD4H8D1wBfa2+TUpoDvl0ulyRJ69B1OKeUfgnYBbyIoit7AdgJzKzYdKbc7kki4taImIqIqenp6fWXWJKkEdfTaO2U0lJK6YvAlcBbgBYwsWKzCWB2lffemVI6kFI6MDk5ud7ySpI08tY7lWqM4pzzIeC69sKI2NGxXJIkrcOa4RwRl0XEayJiZ0RsjoiXAa8F/gz4DHBtRNwcEduAtwNfdzCYJEnr103LOVF0YT8CPAH8JvDvUkr/M6U0DdwMvLNcdyPwmgGVVZKkRlhzKlUZwC++wPovAFdXWShJkprMy3dKkpQZw1mSpMwYzpIkZcZwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMmM4S5KUGcNZkqTMGM6SJGXGcJYkKTOGsyRJmTGcJUnKjOEsSVJmDGdJkjJjOEuSlBnDWZKkzBjOkiRlxnCWJCkzhrMkSZkxnCVJyozhLElSZgxnSZIyYzhLkpQZw1mSpMwYzpIkZcZwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMmM4S5KUGcNZkqTMGM6SJGXGcJYkKTOGsyRJmTGcJUnKzJrhHBHjEfH+iHg4ImYj4qsR8fJy3f6ISBHR6njcMfhiS5I0usa63Oa7wIuB7wCvAD4VET/Wsc2elNLpAZRPkqTGWbPlnFKaSykdTCk9lFI6k1L6Y+BB4IbBF0+SpObp+ZxzRFwOPBM41LH44Yh4JCI+GBF7z/O+WyNiKiKmpqen11lcSZJGX0/hHBFbgI8BH04pHQaOAs8F9lG0pHeV68+RUrozpXQgpXRgcnKyv1JLkjTCujnnDEBEbAI+AiwCtwGklFrAVLnJkYi4DfhBREyklI5XXVhJkpqgq3COiADeD1wOvCKldOo8m6b2WyoomyRJjdRty/l9wLOBl6aUTrYXRsSNwDHg74GLgfcC96aUZqouqCRJTdHNPOd9wJuB64FHO+Yz3wJcBfwpMAs8ACwArx1geSVJGnlrtpxTSg9z4W7qT1RXHEmS5OU7JUnKjOEsSVJmDGdJkjJjOEuSlBnDWZKkzBjOkiRlxnCWJCkzhrMkSZkxnCVJyozhLElSZgxnSZIyYzhLkpQZw1mSpMwYzpIkZcZwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMmM4S5KUGcNZkqTMGM6SJGXGcJYkKTOGsyRJmTGcJUnKjOEsSVJmDGdJkjJjOEuSlBnDWZKkzBjOkiRlxnCWJCkzhrMkSZkxnCVJyozhLElSZgxnSZIyYzhLkpQZw1mSpMysGc4RMR4R74+IhyNiNiK+GhEv71h/U0QcjogTEXFPROwbbJElSRpt3bScx4DvAi8GdgN3AJ+KiP0RsRe4q1x2CTAFfHJAZZUkqRHG1togpTQHHOxY9McR8SBwA3ApcCil9GmAiDgIHI2Iq1NKh6svriRJo6/nc84RcTnwTOAQcA3wtfa6Msi/XS6XJEnr0FM4R8QW4GPAh8uW8U5gZsVmM8CuVd57a0RMRcTU9PT0essrSdLI6zqcI2IT8BFgEbitXNwCJlZsOgHMrnx/SunOlNKBlNKBycnJdRZXkqTR11U4R0QA7wcuB25OKZ0qVx0CruvYbgfwjHK5JElah25bzu8Dng28MqV0smP5Z4BrI+LmiNgGvB34uoPBJElav27mOe8D3gxcDzwaEa3ycUtKaRq4GXgn8ARwI/CaQRZYkqRR181UqoeBuMD6LwBXV1koSZKazMt3SpKUGcNZkqTMGM6SJGXGcJYkKTOGsyRJmTGcJUnKzJpTqSQNz754lF2cqLsYkmpmOEsZ+dWxT/BPNn0DFt8AW3fUXRxJNbFbW8rIFfE4e2IO/vbjdRdFUo0MZykjk1HegfUr74MzZ+otjKTaGM5SNhJ7meHBM5fDD78Nf/+5ugskqSaGs5SJCeYYj9N8fOkmmLgS/ur36y6SpJoYzlIm2l3aR9Il8A9vgsf+ruYSSaqLo7WlTFwWxwCYZjdsH4OTT0BKEOe9KZykEWXLWcrEXoqW82NpD2y/GJYW4ZRznqUmMpylTLS7tY+m3UU4Q9F6ltQ4hrOUick4xmLazAw7OsL5WL2FklQLw1nKxF5mmGYPELacpYYznKVMTMYM02l38cJwlhrNcJYyMRnHivPNANv3FM+Gs9RIhrOUiaLlXIayLWep0QxnKQdnlriE48UcZ4AtF8HmrYaz1FCGs5SDEz9kLM6c7daOclCY4Sw1kuEs5aB1BOBstzYYzlKDGc5SDuYeAzg7WhsMZ6nBDGcpB60inI+yMpy9CInURIazlIPVurW37YF5w1lqIsNZykHrMU6kcebYdnaZ3dpSYxnOUg5aj3E0TQAdt4fcfjEstuD0Ym3FklQPw1nKwdw0j3eeb4azVwmza1tqHMNZysHCLLNp+/LL/bffzb/57EMA3PTOz9ZUKEl1MZylHCy2aLH9SYuOsROAPbTqKJGkGhnOUg4WWsylbU9adCyV4RyGs9Q0hrOUg8XZc1rOM+wAYA9zdZRIUo0MZ6luKcHCueF8LJXhbMtZahzDWarbqZOQzpzTrT3LRZxJwW7DWWocw1mq22IRvitbzolNzLCD3XZrS41jOEt1W5gFoJW2n7PqWNrBnjCcpabpKpwj4raImIqIhYj4UMfy/RGRIqLV8bhjYKWVRlEZzk+6dGdphp1OpZIaaKzL7b4PvAN4GXDun/ewJ6V0urJSSU1ynm5tKKZT7YnZYZdIUs26ajmnlO5KKX0WeHzA5ZGap91yTqu1nHc4lUpqoKrOOT8cEY9ExAcjYu9qG0TErWXX+NT09HRFHyuNgIXzt5yPp4uY8Jyz1Dj9hvNR4LnAPuAGYBfwsdU2TCndmVI6kFI6MDk52efHSiNk8fwDwubYzg7mh10iSTXr9pzzqlJKLWCqfHkkIm4DfhAREyml432XTmqCsuW82oCwVtrGeJwubhs5tnXYJZNUk6qnUqXyOS64laSzFmaB4ATj56xaDuxFR2xLTdLtVKqxiNgGbAY2R8S2ctmNEfGsiNgUEZcC7wXuTSnNDLLQ0khZbMHWnaRVvo6Gs9RM3bac3wacBG4HXlf++23AVcCfArPAA8AC8NrqiymNsIVZGN+56qq59nnoBcNZapKuzjmnlA4CB8+z+hNVFUZqpIVZGN+16ipbzlIzeflOqW5lt/ZqWslwlprIcJbqttA6b7f2iXbL2W5tqVEMZ6luiy0Yn1h11fKFSWw5S41iOEt1Wzh+3m7t5Ut62nKWGsVwlup2gW7tsy1nb34hNYnhLNXtAgPCFtjCUgpY9PraUpMYzlKdTi/A0uJ5p1JBMMd2u7WlhjGcpTq1Q/e84QwttjkgTGoYw1mqU/tc8nm6taG8StiC55ylJjGcpTp10XKeY9xzzlLDGM5Sndot4vOM1oay5Wy3ttQohrNUp3bobr1Qy3mbA8KkhjGcpTott5wvNCBsu/OcpYYxnKU6ddGtfSJ5zllqGsNZqtNyt/b5w7nlPGepcQxnqU4La4fzXNoGSwuwdGpIhZJUN8NZqtPiLGy5CDaPnXeTufb1tZ3rLDWG4SzVaWH2gq1mKK8QBp53lhrEcJbqdIE7UrWdaN820rnOUmMYzlKdFlsXnEYFHS1nB4VJjWE4S3VamL3gBUigvEIYONdZahDDWarT4trd2nOec5Yax3CW6rQ4B1t3XHCTObu1pcYxnKU6LbTWHK19tlvbcJaawnCW6rQ41/1UKuc5S41hOEt1SaloDa/RrT3PVohNtpylBjGcpbqcOgGkNQeEQRStaweESY1hOEt1Wb6u9oVbzsU2Ox0QJjWI4SzVZfmOVBee5wwUrWvnOUuNYThLdVm05SxpdYazVJf2OeQ1zzlTBLjnnKXGMJylurTDdo2pVEBx/W1Ha0uNYThLdWnPW+66W9tzzlJTGM5SXXpqOe+05Sw1iOEs1aWnAWGec5aaxHCW6rIczt0MCNsFp+dh6fRgyyQpC4azVJeFFmzeCmNb1962PaLbuc5SI3QVzhFxW0RMRcRCRHxoxbqbIuJwRJyIiHsiYt9ASiqNmi5uerGsvZ1znaVG6Lbl/H3gHcAHOhdGxF7gLuAO4BJgCvhklQWURtbi2reLXNY+L+15Z6kRxrrZKKV0F0BEHACu7Fj1auBQSunT5fqDwNGIuDqldLjiskqjZbHV3QVIoJjn3H6PpJHX7znna4CvtV+klOaAb5fLJV3I4lx3I7Who1vbc85SE/QbzjuBmRXLZoBzruQfEbeW562npqen+/xYaQQsrH0v52XLA8JsOUtN0G84t4CJFcsmgHP+vE8p3ZlSOpBSOjA5Odnnx0ojYD0DwjznLDVCv+F8CLiu/SIidgDPKJdLupDF2XWM1rZbW2qCbqdSjUXENmAzsDkitkXEGPAZ4NqIuLlc/3bg6w4Gk7qwONfDgDC7taUm6bbl/DbgJHA78Lry329LKU0DNwPvBJ4AbgReM4BySqOnl3POWy6C2OQ8Z6khup1KdRA4eJ51XwCurq5IUgMsnYKlheKynN2IKLq2PecsNYKX75TqsHxHqi5bzu1tvXyn1AiGs1SHXu5I1bZ1p93aUkMYzlId2i3nbgeEtbd1QJjUCIazVIeFHm4X2WbLWWoMw1mqQy/3cm5zQJjUGIazVIf1nHMe3+mAMKkhuppKJaliZQv4Jb8zxUPpe929x25tqTFsOUt1KC/DOZe2df8eB4RJjWE4S3UoW85zbO/+PVt3wul5WDo9oEJJyoXhLNWhDOeTbO3+PVu9vrbUFIazVIfFFnNpnNTLV9CbX0iNYThLdVhs9dalDR23jTScpVFnOEt1WChazj1Z7tZ2rrM06gxnqQ6Lc723nJe7tZ3rLI06w1mqw2KLOXqYRgV2a0sNYjhLdVhscaLXbu3xXcvvlTTaDGepDvPHOU4Pl+4Ep1JJDWI4S3WYn2E29Tpauwxzu7WlkWc4S8OWEszPrKPlvAMIW85SAxjO0rCdnoczp5hNF/X2vghvfiE1hOEsDdv8DADH6TGcwZtfSA1hOEvDNn8cgOO9tpyh6No2nKWRZzhLw1a2nGfX03K2W1tqBMNZGraFslt7PS3n8V22nKUGMJylYevnnLMtZ6kRDGdp2NrhnHqcSgWec5YawnCWhq0cEDbb640vwNHaUkMYztKwzc/ApjFO0uO1tcFubakhDGdp2BaOw/gEEL2/d9tuOH0STi9WXixJ+TCcpWGbnylCdj22X1zu41h15ZGUHcNZGrb547BtYn3vbYfzySeqK4+k7BjO0rD103Letqd4PmnLWRplhrM0bFV0a9tylkaa4SwN28JxGF9vOJctZ885SyPNcJaGzZazpDUYztIwLZ0uLiKy3gFh7VA3nKWRZjhLw7RQXB1s3S3nTZuL9zogTBpphrM0TO1wHl9nyxmKEdu2nKWRVkk4R8S9ETEfEa3y8c0q9iuNnPKmF+tuOUNx3tlwlkZalS3n21JKO8vHsyrcrzQ6lsO5j5bz9osdrS2NOLu1pWGa7/OcMxTTqWw5SyOtynB+V0QcjYgvRcRLVq6MiFsjYioipqanpyv8WGkDqaxb25azNMqqCuf/BFwFPAW4E/ijiHhG5wYppTtTSgdSSgcmJycr+lhpg6liQFj7nHNK1ZRJUnYqCeeU0l+llGZTSgsppQ8DXwJeUcW+pZHSbjn3O1o7LcHCbDVlkpSdQZ1zTqzrZrXSiJs/Dlt3wuax9e/D20ZKI6/vcI6IPRHxsojYFhFjEXEL8E+Bz/VfPGnE9HPpzjYv4SmNvD7+fF+2BXgHcDWwBBwGXpVScq6ztNL8sf66tOHszS8MZ2lk9R3OKaVp4LkVlEUafQvHK2w5260tjSrnOUvDND/T3wVIwG5tqQEMZ2mYTjxxNlzXa5v3dJZGneEsDUtK0DoCOy/vbz9btsPmcVvO0ggznKVhmT8GSwuw64r+9hPhzS+kEWc4S8PSeqx47rflDOX1te3WlkaV4SwNy+yjxfPOy/rfly1naaRVMc9ZUjeWW869d2vvv/3uJ71+6LqL4dh3qyiVpAzZcpaGpVVhy3nbHkdrSyPMcJaGpXUExrb1fxESsFtbGnGGszQss0eKVnNUcE+Y7RfDYgtOL/S/L0nZMZylYWkdWdf55lVN/EjxfPx71exPUlYMZ2lYWo9Vc74ZYPeVxfOM4SyNIsNZGpbWo/1fgKRtOZwfqWZ/krJiOEvDcHqhGMBVxQVI4Gy3tuEsjSTDWRqG5TnOFXVrb9kOOybhuOEsjSLDWRqGPi5Acl4TT7HlLI0ow1kahiovQNK2+0rDWRpRhrM0DK0jxXNVA8IAdj+1COeUqtunpCwYztIwzB4BojhPXJXdTykuRDI/U90+JWXBcJaGoXUELroUNm+pbp9Op5JGluEsDUPrSHXTqNp2P7V49iph0sgxnKVhaB2BXRWH88RTiucZbx0pjRrDWRqGme9VO40Kipb4pi12a0sjyHCWBu3ED4upVJc9u9r9btpUXCnMcJZGjuEsDdqj9xfPV1xb/b53X+nNL6QRZDhLg3bkgeL58h+rft9eiEQaSYazNGiPPlCcH95Z4Rzntt1XFqO1zyxVv29JtTGcpUE7cj9cPoAubYBL/xGkJZj+5mD2L6kWhrM0SKcX4bHDgznfDPC0G4vn73x5MPuXVAvDWRqko9+CM6cGc74Z4OKnF1O0Hv7LwexfUi3G6i6ANNLag8GuuJb9t99d2W479/XQDc+H73ylsn1Lqp8tZ2mQHr0fNo8X54YH5WkvgOOPwLHvDO4zJA2V4SwN0pEH4LKrYfMAO6n2Pb94tmtbGhmGszQop+bh+38LVwzofHPbZT8K47sdFCaNEMNZGpRDn4H5Y3Dtzw72czZthqc+z5azNEIMZ2kQUoK//gPY+yy46iWD/7x9L4Cj34THvz34z5I0cIazNAiPTMH3vwrPexNEDP7zrnstbNkBn79j8J8laeAqCeeIuCQiPhMRcxHxcET8fBX7lTasv/4DGJ8oQnPA9t9+N/t//W9494lXwjfvhv/7hYF/pqTBqmoI6e8Ci8DlwPXA3RHxtZTSoYr2L20MKcG974L7Pw3Pv439v/bnQ/voDyy9nJ/bfA9P/5Pb4fV/BBP/YGifLalafbecI2IHcDNwR0qplVL6IvC/gH/V776l7KUEi3PwxMNw/x/Cx38O/vw34PrXwU2/NtSiLLKFO06/gYWjD9L6rev5rf/8Rl79q/+1uJ/0qXk4c2ao5ZG0fpFS6m8HEc8BvpxS2t6x7D8AL04pvXK19xw4cCBNTU319bnLnngIfu8FFeyov5/D2d1UtJ8qypNTWSCv8lRZlnQ29I6n7fz306/izqWfAYZwrnkVT4sjvG3so/zk5vvOWXcqbeY0mzmzjrLt2OoFBZcNYxyB6vfGz8Pl11S2u4i4L6V0oKttKwjnFwGfTild0bHsTcAtKaWXdCy7Fbi1fPksoKrb6OwFjla0r43A+o426zu6mlRXsL6r2ZdS6uresVX8KdwCJlYsmwBmOxeklO4E7qzg854kIqa6/UtkFFjf0WZ9R1eT6grWt19VjNb+FjAWEZ0XD74OcDCYJEnr0Hc4p5TmgLuA/xIROyLiJ4B/AXyk331LktREVV2E5JeA7cBjwCeAtwxxGlXlXeWZs76jzfqOribVFaxvX/oeECZJkqrl5TslScqM4SxJUmayD+dertsdEX8SEa2Ox2JE3N+x/qGIONmx/vPDqUX3eqzvwYg4taLOV3Wsvz4i7ouIE+Xz9cOpRfd6rO9bI+KBiJiNiAcj4q0r1md3fLutXxR+IyIeLx/viTh7pYuNcCyhp/puuGO5mh7qu+G/q9BTfUfhd/FtETEVEQsR8aE1tv2ViHg0ImYi4gMRMd6xbn9E3FMe28MR8dKuCpBSyvpBMcDsk8BO4IXADHBNl++9F3h7x+uHgJfWXaeq6gscBD56nnVbgYeBXwHGgV8uX2+tu4591Pc/Av+YYn7+s8r6vCbn49tt/YA3U1yY50rgKcA3gF/cSMeyx/puuGPZZ303/He1l/qu8r6N+Lv41cCrgPcBH7rAdi8DjgDXABeXdX13x/q/BH6bYtD0zcAxYHLNz6/7B7DGD2cHxQ01ntmx7COdFb/Ae/cDS8DTN8p/iF7ru8YX/ieB71EO+iuXfQf4qbrrWcXxLbd9L/A7uR7fXuoHfBm4teP1G4GvbJRj2e/xzP1YVnB8N/R3tZ/juxF/F68o/zu4cDh/HPj1jtc3AY+W/34msADs6lj/F5R/eF/okXu39jOBpZTStzqWfY3iL5S1/ALwFymlB1cs/1hETEfE5yPiuqoKWpH11PeVEfHDiDgUEW/pWH4N8PVU/m8ofX2NfQ3buo9v2eX7Is692E1Ox7eX+l1Trlttu41wLGGdx3ODHMvV9FrfjfxdhfV/Xzfi7+JerPbdvTwiLi3X/b+U0uyK9Wse29zDeSdFt0mnGWBXF+/9BeBDK5bdQvFX3D7gHuBzEbGnvyJWqtf6fgp4NjAJvAl4e0S0byDcz89uWPop40GK/78f7FiW2/HtpX4rt50BdpbBtRGOJay/nAfJ/1iuppf6bvTvKqy/nBvxd3EvVvvuQvFzWfexrTWcI+LeiEjneXyRLq/bvcp+XwhcAfxh5/KU0pdSSidTSidSSu+i6Pt/UXU1urCq65tS+kZK6fsppaWU0peB/wb8bLl6XT+7Kg3w+N5G8YX/6ZTSQnt53cd3Fb3Ub+W2E0CrbE3Vfiy71HM5N9CxXE3X9c39u9ql9RzfLH8XV2y17y4UP5d1H9tawzml9JKUUpzn8ULWf93u1wN3pZRaaxWBId7Xb4D1Xf4IztbnEPDjZcur7cd72FffBlHfiHgDcDtwU0rpkbWKQF33bSz0Ur9D5brVtqv9WHapp+O5wY7lavr5vmb1Xe3Seuqb5e/iiq323T2SUnq8XHdVROxasX7tY1v3yfa1HsD/oBghuAP4CdYYHUgxIu4Y8M9WLH9a+f6twDbgrcA0cGnddVxvfSmuYX4xxX/q51EMKnl9ua49AvTfUowAvY0MR4D2WN9bgEeBZ6+yLsvj2239gF8E/o5ipPaPlF/elaO1sz6WPdZ3wx3LPuu74b+rvdS33Haj/y4eK8v3LoqBb9uAsVW2+6ny//KPlsf4z3jyaO2vAL9Zvv9fMgqjtcuKXQJ8FpijGMH48x3rXkTR9de5/WvL/9ixYvk1FIMs5oDHgf8DHKi7fv3Ut/ySPE7RdXIY+OUV+3oOcB9wEvgb4Dl116/P+j4InCrr2378fs7H93z1W6VuAbwH+GH5eA9PHr2b/bHssb4b7lj2Wd8N/13tpb7lso3+u/ggRYu+83GQ4o+LFvC0jm3/PcV0quMUYyfGO9btp5hedZJiumRXo9S9trYkSZnJfbS2JEmNYzhLkpQZw1mSpMwYzpIkZcZwliQpM4azJEmZMZwlScqM4SxJUmYMZ0mSMvP/AWmIiyIbybo7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.0084 mean of per-base difference in sequence length\n",
      "     0.0213 std dev of per-base difference in sequence length\n"
     ]
    }
   ],
   "source": [
    "if not (args.mean and args.std):\n",
    "    print(\" - determining statistics about per-base difference ([align. subject len] - [align. query len]) / [align. query len] al from genome alignments\")\n",
    "    sequence_length_stats(gn_algn_df)\n",
    "    print(\"{:>11.4f} mean of per-base difference in sequence length\".format(args.mean))\n",
    "    print(\"{:>11.4f} std dev of per-base difference in sequence length\".format(args.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.concat([ad_algn_df, gn_algn_df], keys=['ad', 'gn'])\n",
    "d_ad = pd.merge(pd.DataFrame(reads.index, columns=['rid']).set_index('rid', drop=False), \n",
    "                ad_algn_df.set_index('qid'),\n",
    "                how='outer', left_index=True, right_index=True, sort=False)\n",
    "df = pd.merge(d_ad, \n",
    "              gn_algn_df.set_index('qid'), \n",
    "              how='outer', left_index=True, right_index=True, sort=False, suffixes=('_ad', '_gn'))\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "sel = df.subj_ad.notnull() & \\\n",
    "      df.subj_gn.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13022034         entities after joining\n",
      "       3737   0.0 % not aligning against both an adapter and a genomic seq\n",
      "     219593  98.4 % reads remaining that contain potential transitions between adapter and genomic seq.\n",
      "   13018297 100.0 % potential transitions remaining\n"
     ]
    }
   ],
   "source": [
    "print('{:>11} {:>7} entities after joining'.format(len(df), \"\"))\n",
    "c = sum(np.logical_not(sel))\n",
    "print('{:>11} {:>5.1f} % not aligning against both an adapter and a genomic seq'.format(c, c/len(df)*100.))\n",
    "c = len(set(df.loc[sel, 'rid']))\n",
    "print('{:>11} {:>5.1f} % reads remaining that contain potential transitions between adapter and genomic seq.'.format(c, c/len(reads)*100.))\n",
    "c = sum(sel)\n",
    "print('{:>11} {:>5.1f} % potential transitions remaining'.format(c, c/len(df)*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - deleting all entries from dataframe that are not potential transitions\n"
     ]
    }
   ],
   "source": [
    "# deleting non-potential transitions at this point so that all procentual values are with respect to potential ones only\n",
    "print(\" - deleting all entries from dataframe that are not potential transitions\")\n",
    "df = df.drop(df.index[np.logical_not(sel)]).astype({\"qlen_ad\":np.int32, \"qst_ad\":np.int32, \"qen_ad\":np.int32, \"slen_ad\":np.int32,\n",
    "                                                   \"sst_ad\":np.int32, \"sen_ad\":np.int32, \"mlen_ad\":np.int32, \"blen_ad\":np.int32, \"mapq_ad\":np.int32,\n",
    "                                                   \"qlen_gn\":np.int32, \"qst_gn\":np.int32, \"qen_gn\":np.int32, \"slen_gn\":np.int32,\n",
    "                                                   \"sst_gn\":np.int32, \"sen_gn\":np.int32, \"mlen_gn\":np.int32, \"blen_gn\":np.int32, \"mapq_gn\":np.int32})\n",
    "sel = df.subj_ad.notnull() & \\\n",
    "      df.subj_gn.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6507849  50.0 % of total potential transpositions are adapter -> genome\n",
      "    6508319  50.0 % of total potential transpositions are genome -> adapter\n",
      " - filter potential subject transitions based on alignment lengths\n",
      "       3123   0.0 % of total potential transpositions filtered\n",
      "       1575   0.0 % bc adapter alignment length < 50\n",
      "       1548   0.0 % bc genome alignment length < 50\n",
      "   13015174 100.0 % potential transitions remaining\n"
     ]
    }
   ],
   "source": [
    "# identify if row describes a transition from adapter to genomic sequence or vise versa\n",
    "df.loc[sel,'trans_order'] = 0 # qst_ad == qst_gn\n",
    "df.loc[sel & (df.qst_ad < df.qst_gn), 'trans_order'] = 1 # adapter -> genome\n",
    "df.loc[sel & (df.qst_ad > df.qst_gn), 'trans_order'] = -1 # genome -> adapter\n",
    "c = sum(df[sel].qst_ad < df[sel].qst_gn)\n",
    "print('{:>11} {:>5.1f} % of total potential transpositions are adapter -> genome'.format(c, c/len(df[sel])*100.))\n",
    "c = sum(df[sel].qst_ad > df[sel].qst_gn)\n",
    "print('{:>11} {:>5.1f} % of total potential transpositions are genome -> adapter'.format(c, c/len(df[sel])*100.))\n",
    "\n",
    "# select all entries with an sufficiently long alignment to both the adapter and the genome\n",
    "print(' - filter potential subject transitions based on alignment lengths')\n",
    "sel_ = (df.blen_ad >= args.min_adapter_blen) & \\\n",
    "       (df.blen_gn >= args.min_genome_blen)\n",
    "c = sum(sel & np.logical_not(sel_))\n",
    "print('{:>11} {:>5.1f} % of total potential transpositions filtered'.format(c, c/len(df)*100.))\n",
    "c = sum(sel & np.logical_not(df.blen_ad >= args.min_adapter_blen))\n",
    "print('{:>11} {:>5.1f} % bc adapter alignment length < {}'.format(c, c/len(df)*100., args.min_adapter_blen))\n",
    "c = sum(sel & np.logical_not(df.blen_gn >= args.min_genome_blen))\n",
    "print('{:>11} {:>5.1f} % bc genome alignment length < {}'.format(c, c/len(df)*100., args.min_genome_blen))\n",
    "sel &= sel_\n",
    "c = sum(sel)\n",
    "print('{:>11} {:>5.1f} % potential transitions remaining'.format(c, c/len(df)*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(nb_workers=args.processes, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - determine query seq start and end in read coordinates\n",
      "        190   0.0 % of remaining potential transpositions had < 12 matching terminal bases\n",
      "   13014984 100.0 % potential transitions remaining\n"
     ]
    }
   ],
   "source": [
    "# determine query seq start and end in read coordinates\n",
    "print(\" - determine query seq start and end in read coordinates\")\n",
    "df = get_query_seq(df, sel)\n",
    "c = sum(sel & (df.query_st.isnull() | df.query_en.isnull()))\n",
    "print('{:>11} {:>5.1f} % of remaining potential transpositions had < {} matching terminal bases'.format(c, c/sum(sel)*100., args.wordsize))\n",
    "sel &= df.query_st.notnull() & df.query_en.notnull()\n",
    "c = sum(sel)\n",
    "print('{:>11} {:>5.1f} % potential transitions remaining'.format(c, c/len(df)*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - exclude entries based on query sequence length (adapter-genome alignment distance) from analysis\n",
      "     129121   1.0 % of remaining potential transpositions removed due to query seq. length < 0 nt (alignment overlap of more than 5 nt)\n",
      "   10456655  80.3 % of remaining potential transpositions removed due to query seq. length > 200 nt\n",
      "    2429208  18.7 % potential transitions remaining\n"
     ]
    }
   ],
   "source": [
    "# filter out entries with query seq. that are too long -> distance between adapter and genome alignment is too large\n",
    "print(\" - exclude entries based on query sequence length (adapter-genome alignment distance) from analysis\")\n",
    "too_short = (df.query_en - df.query_st) < 0.\n",
    "too_long = (df.query_en - df.query_st) > args.max_dist\n",
    "c = sum(too_short)\n",
    "print('{:>11} {:>5.1f} % of remaining potential transpositions removed due to query seq. length < 0 nt (alignment overlap of more than {} nt)'.format(c, c/sum(sel)*100., args.strip))\n",
    "c = sum(too_long)\n",
    "print('{:>11} {:>5.1f} % of remaining potential transpositions removed due to query seq. length > {} nt'.format(c, c/sum(sel)*100., args.max_dist))\n",
    "sel &= np.logical_not(too_short) & np.logical_not(too_long)\n",
    "c = sum(sel)\n",
    "print('{:>11} {:>5.1f} % potential transitions remaining'.format(c, c/len(df)*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - determining query sequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71946397086c41648dc9e726636e6e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=303651), Label(value='0 / 303651')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set query seq for each row\n",
    "print(\" - determining query sequences\")\n",
    "df.loc[sel, 'query_seq'] = df[sel].parallel_apply(lambda row: reads.loc[row.rid].seq[int(row.query_st) : int(row.query_en)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - determining reference sequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aede926294454112b856ddac4364118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=303651), Label(value='0 / 303651')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f02ab99be84543a28e6b0ea04f60b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=303651), Label(value='0 / 303651')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" - determining reference sequences\")\n",
    "df.loc[sel, 'max_ref_len'] = ((df[sel].query_en - df[sel].query_st) * (1 + args.mean + 3 * args.std) + 0.5).round()\n",
    "df.loc[sel, 'ref1'] = df.loc[sel].parallel_apply(lambda row: get_ref1(row), axis=1)\n",
    "df.loc[sel, 'ref2'] = df.loc[sel].parallel_apply(lambda row: get_ref2(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - aligning\n"
     ]
    }
   ],
   "source": [
    "print(' - aligning')\n",
    "# initialize the necessary data structures\n",
    "wd = !pwd\n",
    "clib = os.path.join(str(wd[0]), \"align.so\")\n",
    "\n",
    "nd_pp = np.ctypeslib.ndpointer(dtype=np.uintp, ndim=1, flags='C_CONTIGUOUS')\n",
    "align = ct.CDLL(clib).align\n",
    "align.argtypes = [ct.c_char_p, ct.c_char_p, \n",
    "                  ct.c_short, ct.c_short, ct.c_short,\n",
    "                  ct.c_short, ct.c_short, ct.c_short, ct.c_short,\n",
    "                  nd_pp, nd_pp, nd_pp, nd_pp, nd_pp, nd_pp, nd_pp]\n",
    "align.restype = ct.c_int\n",
    "\n",
    "backtrace = ct.CDLL(clib).backtrace2\n",
    "backtrace.argtypes = [nd_pp, nd_pp, nd_pp, nd_pp, nd_pp, nd_pp,\n",
    "                      ct.c_short, ct.c_short, ct.c_short,\n",
    "                      nd_pp]\n",
    "backtrace.restype = ct.c_int\n",
    "\n",
    "ct.CDLL(clib).init()\n",
    "\n",
    "max_subj_len = 2*int((args.max_dist * (1 + args.mean + 3 * args.std) + 0.5).round())\n",
    "scores = np.empty(shape=(max_subj_len+1, args.max_dist+1), dtype=np.int16)\n",
    "ops = np.empty(shape=(6,max_subj_len+1, args.max_dist+1), dtype=np.bool_)\n",
    "#m, mm, go, ge = 1, -2, -4, -1\n",
    "# initialize the fields that never change\n",
    "scores[0,0] = 0\n",
    "scores[0,1:] = np.arange(args.gap_open + args.gap_extension, args.gap_open + (args.max_dist+1)*args.gap_extension, args.gap_extension)\n",
    "ops[:,0,:] = False\n",
    "ops[:,:,0] = False\n",
    "ops[0,0,1:] = True\n",
    "ops[2,0,0] = True\n",
    "ops[5,0,0] = True\n",
    "if scores.flags['C_CONTIGUOUS'] == False:\n",
    "    scores = np.ascontiguousarray(scores, dtype=scores.dtype)\n",
    "if ops.flags['C_CONTIGUOUS'] == False:\n",
    "    ops = np.ascontiguousarray(ops, dtype=ops.dtype)\n",
    "scores_pp = (scores.ctypes.data + np.arange(scores.shape[0]) * scores.strides[0]).astype(np.uintp)\n",
    "ops_pp = [(ops[i].ctypes.data + np.arange(ops[i].shape[0]) * ops[i].strides[0]).astype(np.uintp) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(nb_workers=4, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ebc9c4bfbf47d7b817e0165ee2485d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3254575), Label(value='0 / 3254575…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c3eb6eb7816a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start the alignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_align_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;31m# if the two alignments are fitting together perfetly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             )\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mmessage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mINPUT_FILE_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/nanopore/bin/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got end of file during message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the alignment\n",
    "df = df.parallel_apply(lambda row: c_align_row(row), axis=1)\n",
    "df.loc[sel & (df.query_seq.str.len() > 0), 'norm_score'] = df[sel].score / df[sel].query_seq.str.len()\n",
    "df.loc[sel & (df.query_seq.str.len() == 0), 'norm_score'] = args.match # if the two alignments are fitting together perfetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for upper, lower in [(1., .9), (.9, .8), (.8, .7), (.7, .6), (.6, .5), (.5, 0.)]:\n",
    "    c = sum(sel & (upper >= df.norm_score) & (df.norm_score > lower))\n",
    "    print('{:>11} {:>5.1f} % with {} >= normed score > {}'.format(c, c/sum(sel)*100., upper, lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_norm_score_distribution(df, title, nbins=50):\n",
    "    x, y = df.query_seq.str.len(), df.norm_score\n",
    "    \n",
    "    # definitions for the axes\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    spacing = 0.005\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "    # start with a rectangular Figure\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    ax_scatter = plt.axes(rect_scatter)\n",
    "    ax_scatter.tick_params(direction='in', top=True, right=True)\n",
    "    ax_histx = plt.axes(rect_histx)\n",
    "    ax_histx.tick_params(direction='in', labelbottom=False)\n",
    "    ax_histy = plt.axes(rect_histy)\n",
    "    ax_histy.tick_params(direction='in', labelleft=False)\n",
    "\n",
    "    ax_scatter.scatter(x, y, s=1., alpha=0.05)\n",
    "\n",
    "    ax_histx.hist(x, bins=nbins)\n",
    "    ax_histy.hist(y, bins=nbins, orientation='horizontal')\n",
    "\n",
    "    ax_histx.set_xlim(ax_scatter.get_xlim())\n",
    "    ax_histy.set_ylim(ax_scatter.get_ylim())\n",
    "    \n",
    "    ax_scatter.set_xlabel(\"distance between alignments / nt\")\n",
    "    ax_scatter.set_ylabel(\"qlen normalized alignment score\")\n",
    "    ax_histx.set_ylabel(\"bin count\")\n",
    "    ax_histy.set_xlabel(\"bin count\")\n",
    "    \n",
    "    ax_histx.set_title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if args.plot:\n",
    "    plot_norm_score_distribution(df[sel], \"all data\")\n",
    "    plot_norm_score_distribution(df[sel & (df.trans_order == 1.)], \"adapter -> genome transitions\")\n",
    "    plot_norm_score_distribution(df[sel & (df.trans_order == -1.)], \"genome -> adapter transitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(args.prefix + \".alignment.df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
